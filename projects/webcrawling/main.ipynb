{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawling import *\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "# need dnspython, PyOpenSSL, requests and service_identity for srv and ocsp\n",
    "from urllib import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\n",
    "    \"mongodb+srv://cluster0.c6ccx.mongodb.net\",\n",
    "    authsource=\"$external\",\n",
    "    authmechanism=\"MONGODB-X509\",\n",
    "    tls=True,\n",
    "    tlsCertificateKeyFile=\"../../../mongodb.pem\",\n",
    ")\n",
    "db = client[\"webtoon\"]\n",
    "collection = db[\"data\"]\n",
    "collection_backup = db[\"backup\"]\n",
    "collection_backup2 = db[\"backup2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset collection with backup\n",
    "collection.drop()\n",
    "collection.insert_many(collection_backup.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first process\n",
    "root_url = \"https://comic.naver.com/webtoon/weekday\"\n",
    "bar = ProgressBar(len(html_parser(root_url, dynamic=False).select(\".thumb>a\")))\n",
    "for tag in html_parser(root_url, dynamic=False).select(\".thumb>a\"):\n",
    "    bar.next()\n",
    "    title = tag.select_one(\"img\").attrs[\"title\"]\n",
    "    url = \"https://comic.naver.com\" + tag.attrs[\"href\"]\n",
    "    url_query = get_url_query(url)\n",
    "    weekday = url_query[\"weekday\"]\n",
    "    titleId = url_query[\"titleId\"]\n",
    "    if collection.find_one({\"title\": title}):\n",
    "        collection.update_one({\"title\": title}, {\"$addToSet\": {\"weekday\": weekday}})\n",
    "    else:\n",
    "        collection.insert_one({\"title\": title, \"url\": url, \"weekday\": [weekday], \"titleId\": titleId})\n",
    "len(list(collection.find())) # different from expacted value because of duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add backup\n",
    "pprint(list(collection.find()))\n",
    "collection_backup.drop()\n",
    "collection_backup.insert_many(collection.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# datetime has smaller size than string!\n",
    "print(sys.getsizeof(datetime(2021, 8, 21)), sys.getsizeof(\"2021.08.21\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second process with progressbar\n",
    "first_data = list(collection.find())\n",
    "bar = ProgressBar(len(first_data))\n",
    "for document in first_data:\n",
    "    bar.next()\n",
    "    html = html_parser(document[\"url\"], dynamic=False)\n",
    "    collection.update_one(\n",
    "        {\"title\": document[\"title\"]},\n",
    "        {\n",
    "            \"$set\": {\n",
    "                \"writer\": get_text(html.select_one(\".wrt_nm\")).split(\"/\"),\n",
    "                \"genre\": get_text(html.select_one(\".genre\")).split(\",\"),\n",
    "                \"age\": get_text(html.select_one(\".age\"))\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    target_url = document[\"url\"]\n",
    "    while True:\n",
    "        target_html = html_parser(target_url, dynamic=False)\n",
    "        target_trs = target_html.select(\"table.viewList>tr\")\n",
    "        for target_tr in target_trs:\n",
    "            if target_tr.get(\"class\") is None:\n",
    "                date = datetime.strptime(get_text(target_tr.select_one(\".num\")), \"%Y.%m.%d\")\n",
    "                if date.year == 2020:\n",
    "                    break\n",
    "                if date.year == 2022:\n",
    "                    continue\n",
    "                title = target_tr.select_one(\"td.title>a\")\n",
    "                collection.update_one(\n",
    "                    {\"title\": document[\"title\"]},\n",
    "                    {\n",
    "                        \"$addToSet\": {\n",
    "                            \"episode\": {\n",
    "                                \"no\": int(get_url_query(title.attrs[\"href\"])[\"no\"]),\n",
    "                                \"subno\": get_text(title),\n",
    "                                \"rating\": float(get_text(target_tr.select_one(\".rating_type>strong\"))),\n",
    "                                \"date\": date,\n",
    "                                \"url\":title.attrs[\"href\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                )\n",
    "        else:\n",
    "            next = target_html.select_one(\".next\")\n",
    "            if next is not None:\n",
    "                target_url = \"https://comic.naver.com\" + next.attrs[\"href\"]\n",
    "                continue\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_episode_url =\"https://comic.naver.com/webtoon\"\n",
    "\n",
    "bar = ProgressBar(len(list(collection.find())))\n",
    "for document in collection.find():    \n",
    "    bar.next()\n",
    "    for episode in document.get(\"episode\", []):\n",
    "        collection.update_one(\n",
    "            {\"title\": document[\"title\"], \"episode.no\":episode[\"no\"]},\n",
    "            {\n",
    "                \"$set\":{\n",
    "                    \"episode.$.url\":set_url_query(root_episode_url, {\"titleId\":document[\"titleId\"], \"no\":episode[\"no\"]})\n",
    "                }\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(list(collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib import parse\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "def getJson(url, query={}, init_api_url=\"https://apis.naver.com/commentBox/cbox/web_naver_list_jsonp.json?ticket=comic&pool=cbox3&lang=ko&objectId=183559_517&pageSize=100&page=1&sort=NEW\"):    \n",
    "    # make valid header\n",
    "    parsed_url = parse.urlparse(url)\n",
    "    parsed_url_query = dict(parse.parse_qsl(parsed_url.query))\n",
    "    for key in list(parsed_url_query.keys()): # remove weekday value\n",
    "        if key not in (\"titleId\", \"no\"):\n",
    "            parsed_url_query.pop(key)\n",
    "    comment_url = parse.urlunparse(parsed_url._replace(path=\"/comment/comment\", query=parse.urlencode(parsed_url_query)))\n",
    "    header = {\"referer\":comment_url,\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\"}\n",
    "    print(header)\n",
    "\n",
    "    # get api url using query of init api url\n",
    "    parsed_init_api_url = parse.urlparse(init_api_url)\n",
    "    new_objectId = \"_\".join(parsed_url_query.values())\n",
    "    print(new_objectId)\n",
    "    api_url = set_url_query(parsed_init_api_url, {\"objectId\":new_objectId})\n",
    "    print(api_url)\n",
    "    \n",
    "    # removing useless prefix and subfix\n",
    "    removeElse = re.compile(\"^[^{]+|[^}]+$\")\n",
    "    api_json = json.loads(removeElse.sub(\"\", requests.get(api_url, headers=header).text))\n",
    "    return api_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_expr = {\"$expr\": {\"$gte\": [{\"$divide\": [{\"$size\": \"$episode\"}, {\"$size\": \"$weekday\"}]}, 40]}}\n",
    "preprocess_query = {\"$match\":preprocess_expr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "dateFormat = \"%Y-%m-%dT%H:%M:%S%z\"\n",
    "for document in collection.find():\n",
    "    for i, episode in enumerate(document[\"episode\"]):\n",
    "        while True:\n",
    "            target_url = episode[\"\"]\n",
    "            pagenum = getJson(target_url)[\"result\"][\"pageModel\"][\"lastPage\"]\n",
    "            if i == len(document[\"episode\"])-1:\n",
    "                end_date = datetime(2022,1,1)\n",
    "            else:\n",
    "                end_date = document[\"episode\"][i+1][\"date\"]\n",
    "            comment_data = []\n",
    "            break_seq = False\n",
    "            while pagenum > 0 and not break_seq:\n",
    "                comment_json = getJson(target_url, {\"page\":pagenum})\n",
    "                comment_list = comment_json[\"result\"][\"commentList\"][::-1]\n",
    "                for comment in comment_list:\n",
    "                    if datetime.strptime(comment[\"regTime\"], dateFormat) >= end_date:\n",
    "                        break_seq = True\n",
    "                        break\n",
    "                    comment_data.append({\"userIdNo\":comment[\"userIdNo\"], \"regTime\":comment[\"regTime\"],\"sympathyCount\":comment[\"sympathyCount\"], \"antipathyCount\":comment[\"antipathyCount\"]})\n",
    "            # collection.update_one({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "preprocess_expr = {\"$expr\": {\"$gte\": [{\"$divide\": [{\"$size\": \"$episode\"}, {\"$size\": \"$weekday\"}]}, 40]}}\n",
    "preprocess_query = {\"$match\":preprocess_expr}\n",
    "pre_data = collection.find(\n",
    "    {\"$expr\": {\"$gte\": [{\"$divide\": [{\"$size\": \"$episode\"}, {\"$size\": \"$weekday\"}]}, 40]}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(pre_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating_query = {\"$project\": {\"_id\": 0, \"title\": 1, \"url\": 1, \"avg_rating\": {\"$avg\": \"$rating_info.rating\"}}}\n",
    "max_rating_webtoon = list(\n",
    "    collection.aggregate([avg_rating_query, {\"$sort\": {\"avg_rating\": -1}}, {\"$limit\": 10}])\n",
    ")\n",
    "min_rating_webtoon = list(collection.aggregate([avg_rating_query, {\"$sort\": {\"avg_rating\": 1}}, {\"$limit\": 10}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(max_rating_webtoon)\n",
    "pprint(min_rating_webtoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc(\"font\", family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([data[\"title\"] for data in max_rating_webtoon], [data[\"avg_rating\"] for data in max_rating_webtoon])\n",
    "plt.xticks(rotation=90)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([9.9, 10])\n",
    "plt.show()\n",
    "plt.bar([data[\"title\"] for data in min_rating_webtoon], [data[\"avg_rating\"] for data in min_rating_webtoon])\n",
    "plt.xticks(rotation=90)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 10])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_rating_query = {\"$project\": {\"_id\": 0, \"title\": 1, \"url\": 1, \"std_rating\": {\"$stdDevPop\": \"$rating_info.rating\"}}}\n",
    "max_std_rating_webtoon = list(\n",
    "    collection.aggregate([std_rating_query, {\"$sort\": {\"std_rating\": -1}}, {\"$limit\": 10}])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(max_std_rating_webtoon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for webtoon in max_std_rating_webtoon[:5]:\n",
    "    data = collection.find_one({\"title\": webtoon[\"title\"]})\n",
    "    rating_info = data[\"rating_info\"]\n",
    "    plt.plot(rating_info[\"date\"], rating_info[\"rating\"])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(data[\"title\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for data in collection.find():\n",
    "    time_data = list(map(lambda x: x.timestamp() / 3600 / 24, data[\"rating_info\"][\"date\"]))\n",
    "    rating_data = data[\"rating_info\"][\"rating\"]\n",
    "    result = stats.linregress(time_data, rating_data)\n",
    "    slope, r_squared = result.slope, result.rvalue ** 2\n",
    "    collection.update_one(\n",
    "        {\"title\": data[\"title\"]}, {\"$set\": {\"rating_info.slope\": slope, \"rating_info.r_squared\": r_squared}}\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_sum_of_square(x, y):\n",
    "    stats.linregress(time_data)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_rating_query = {\"$project\": {\"_id\": 0, \"title\": 1, \"url\": 1, \"slope\": \"$rating_info.slope\"}}\n",
    "inc_rating_webtoon = list(collection.aggregate([lin_rating_query, {\"$sort\": {\"slope\": -1}}, {\"$limit\": 10}]))\n",
    "dec_rating_webtoon = list(collection.aggregate([lin_rating_query, {\"$sort\": {\"slope\": 1}}, {\"$limit\": 10}]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dec_rating_webtoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for webtoon in dec_rating_webtoon[:5]:\n",
    "    data = collection.find_one({\"title\": webtoon[\"title\"]})\n",
    "    rating_info = data[\"rating_info\"]\n",
    "    plt.plot(rating_info[\"date\"], rating_info[\"rating\"])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(data[\"title\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_rating_query = {\"$project\": {\"_id\": 0, \"title\": 1, \"url\": 1, \"r_squared\": \"$rating_info.r_squared\"}}\n",
    "min_r_squared_rating_webtoon = list(\n",
    "    collection.aggregate([r_squared_rating_query, {\"$sort\": {\"r_squared\": 1}}, {\"$limit\": 10}])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(collection.aggregate([r_squared_rating_query, {\"$sort\": {\"r_squared\": 1}}]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_r_squared_rating_webtoon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for webtoon in min_r_squared_rating_webtoon[:5]:\n",
    "    data = collection.find_one({\"title\": webtoon[\"title\"]})\n",
    "    rating_info = data[\"rating_info\"]\n",
    "    plt.plot(rating_info[\"date\"], rating_info[\"rating\"])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(data[\"title\"])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9a2a7e76be0666fe27d557e389290381784232b36828a7affb84ce52a0a0717"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pybook': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
